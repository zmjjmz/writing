\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{LIST OF TABLES}{vi}{chapter*.3}}
\citation{calambokidis2008splash}
\@writefile{toc}{\contentsline {chapter}{LIST OF FIGURES}{vii}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{ACKNOWLEDGMENTS}{x}{section*.6}}
\citation{blackmer2000temporal,calambokidis2008splash}
\citation{calambokidis2008splash}
\citation{crall_hotspotter_2013}
\@writefile{toc}{\contentsline {chapter}{ABSTRACT}{xi}{section*.8}}
\citation{baker1993abundant}
\citation{branch2011humpback}
\citation{calambokidis2008splash}
\citation{calambokidis2008splash}
\citation{blackmer2000temporal}
\citation{mizroch1990computer}
\citation{mizroch1990computer,whitehead1990computer}
\citation{hughes2015automated,kniest2010fluke,i3scontour}
\@writefile{toc}{\contentsline {chapter}{\numberline {1.}Introduction}{1}{chapter.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Humpback Whales}{1}{section.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Distinguishing Individual Flukes}{1}{subsection.1.1.1}}
\citation{i3scontour}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Example Flukes}. Example images of humpback whale flukes from the SPLASH \cite  {calambokidis2008splash} dataset. These flukes both have distinctive internal textures (more so on the left). However, the trailing edge on the left is far more distinctive than the trailing edge on the right.\relax }}{2}{figure.caption.10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example_fluke}{{1.1}{2}{\textbf {Example Flukes}. Example images of humpback whale flukes from the SPLASH \cite {calambokidis2008splash} dataset. These flukes both have distinctive internal textures (more so on the left). However, the trailing edge on the left is far more distinctive than the trailing edge on the right.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Current Identification Methods}{2}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Based on Trailing Edge}{2}{subsection.1.2.1}}
\citation{hughes2015automated}
\citation{huele2000finding,beekmans2005comparison,whitehead1990computer}
\citation{whitehead1990computer}
\citation{huele2000finding}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces \textbf  {Uniform Internal Texture}. This image of a humpback fluke shows no clear internal texture, but a distinctive trailing edge.\relax }}{3}{figure.caption.11}}
\newlabel{fig:unclear_texture}{{1.2}{3}{\textbf {Uniform Internal Texture}. This image of a humpback fluke shows no clear internal texture, but a distinctive trailing edge.\relax }{figure.caption.11}{}}
\citation{beekmans2005comparison}
\citation{mizroch1990computer}
\citation{kniest2010fluke}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces \textbf  {Change in Trailing Edge}. The above images show that out of plane rotations of the fluke can obscure it or otherwise make it hard to match. These images are both of the same individual, however in the top image the fluke is rotated slightly towards the camera.\relax }}{4}{figure.caption.12}}
\newlabel{fig:unclear_te}{{1.3}{4}{\textbf {Change in Trailing Edge}. The above images show that out of plane rotations of the fluke can obscure it or otherwise make it hard to match. These images are both of the same individual, however in the top image the fluke is rotated slightly towards the camera.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Based on General Fluke Appearance}{4}{subsection.1.2.2}}
\citation{kniest2010fluke}
\citation{crall_hotspotter_2013}
\citation{lowe2004distinctive}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Method Outline}{5}{section.1.3}}
\citation{calambokidis2008splash}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces \textbf  {Example Keypoint and Trailing Edge Annotation}. This image shows a typical set of fluke keypoints and trailing edge extracted by our algorithm.\relax }}{6}{figure.caption.13}}
\newlabel{fig:example_overlay}{{1.4}{6}{\textbf {Example Keypoint and Trailing Edge Annotation}. This image shows a typical set of fluke keypoints and trailing edge extracted by our algorithm.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}The Dataset}{6}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Thesis Outline}{7}{section.1.5}}
\citation{krizhevsky2012imagenet,szegedy2015going}
\citation{long2015fully,chen2014semantic}
\citation{fan2014learning,schroff2015facenet}
\citation{fukushima1979neural}
\citation{lecun1998gradient}
\citation{hinton2012improving}
\citation{dumoulin2016guide}
\citation{simonyan2014very,sermanet2013overfeat,krizhevsky2012imagenet}
\citation{ioffe2015batch}
\citation{saxe2013exact}
\@writefile{toc}{\contentsline {chapter}{\numberline {2.}Background}{8}{chapter.2}}
\newlabel{sec:background}{{2}{8}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Convolutional Networks}{8}{section.2.1}}
\citation{taigman2014deepface}
\citation{akagi2013facial}
\citation{berretti20113d}
\citation{sun2013deep,nouri2014using}
\citation{ning2005toward,ciresan2012deep,hariharan2014simultaneous}
\citation{long2015fully}
\citation{amini1988using,kass1988snakes}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Facial Keypoint Prediction}{9}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Fully Convolutional Networks}{9}{subsection.2.1.2}}
\citation{Avidan:2007:SCC:1276377.1276390}
\citation{monroy2011beyond}
\citation{fischer2014image,kumar2012leafsnap}
\citation{fischer2014image}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Contour Extraction}{10}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Active Contour}{10}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Seam Carving}{10}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Curvature Measures}{10}{section.2.3}}
\citation{pottmann2007integral}
\citation{sakoe1978dynamic}
\citation{salvador2007fastdtw,lemire2009faster}
\citation{sakoe1978dynamic}
\citation{munich1999continuous}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Dynamic Time Warping}{11}{section.2.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3.}Methods}{12}{chapter.3}}
\newlabel{sec:methods}{{3}{12}{Methods}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Trailing Edge Extraction}{12}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Fluke keypoint prediction}{12}{subsection.3.1.1}}
\citation{simonyan2014very}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {Example Keypoint Prediction}. Example image showing the left tip, bottom of the notch, and right tip located by the keypoint extractor convolutional network.\relax }}{13}{figure.caption.14}}
\newlabel{fig:example_kp}{{3.1}{13}{\textbf {Example Keypoint Prediction}. Example image showing the left tip, bottom of the notch, and right tip located by the keypoint extractor convolutional network.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.1}Network Design}{13}{subsubsection.3.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.2}Training Details}{13}{subsubsection.3.1.1.2}}
\citation{kingma2014adam}
\newlabel{eqn:se_loss}{{3.1}{14}{Training Details}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.3}Evaluation}{14}{subsubsection.3.1.1.3}}
\citation{jaderberg2015spatial}
\citation{Sobel1968}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf  {Example Keypoint Failure}. Example image showing a keypoint extraction failure case from its testing set. Note the difference in pose of the fluke from the success case shown in Figure \ref  {fig:example_kp}. This is an example of a fluke image that violates our assumptions.\relax }}{15}{figure.caption.15}}
\newlabel{fig:example_kp_failure}{{3.2}{15}{\textbf {Example Keypoint Failure}. Example image showing a keypoint extraction failure case from its testing set. Note the difference in pose of the fluke from the success case shown in Figure \ref {fig:example_kp}. This is an example of a fluke image that violates our assumptions.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Basic Trailing Edge Extraction Algorithm}{15}{subsection.3.1.2}}
\newlabel{sec:basic_te}{{3.1.2}{15}{Basic Trailing Edge Extraction Algorithm}{subsection.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf  {Histogram of Keypoint Distances}. This is a histogram of the average distance from predicted keypoints to annotated keypoints on the testing set for the keypoint extraction network. The vast majority of keypoints are predicted within 10 pixels of the true keypoints.\relax }}{16}{figure.caption.16}}
\newlabel{fig:kp128_dist_hist}{{3.3}{16}{\textbf {Histogram of Keypoint Distances}. This is a histogram of the average distance from predicted keypoints to annotated keypoints on the testing set for the keypoint extraction network. The vast majority of keypoints are predicted within 10 pixels of the true keypoints.\relax }{figure.caption.16}{}}
\newlabel{eqn:norm01}{{3.2}{16}{Basic Trailing Edge Extraction Algorithm}{equation.3.1.2}{}}
\newlabel{eqn:te_update}{{3.3}{17}{Basic Trailing Edge Extraction Algorithm}{equation.3.1.3}{}}
\newlabel{eqn:backtrace_update}{{3.4}{17}{Basic Trailing Edge Extraction Algorithm}{equation.3.1.4}{}}
\newlabel{eqn:te_build}{{3.5}{17}{Basic Trailing Edge Extraction Algorithm}{equation.3.1.5}{}}
\newlabel{eqn:te_setup}{{3.6}{17}{Basic Trailing Edge Extraction Algorithm}{equation.3.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces \textbf  {Example Trailing Edge Extraction}. Example of the baseline trailing edge extraction with $n = 2$. Note that the gradient image has a significant black area where the trailing edge is, making this an easy case.\relax }}{18}{figure.caption.17}}
\newlabel{fig:example_te_extract_noscorer}{{3.4}{18}{\textbf {Example Trailing Edge Extraction}. Example of the baseline trailing edge extraction with $n = 2$. Note that the gradient image has a significant black area where the trailing edge is, making this an easy case.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Trailing Edge Scoring}{18}{subsection.3.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.1}Trailing Edge Scoring Architectures}{19}{subsubsection.3.1.3.1}}
\newlabel{sec:te_arch}{{3.1.3.1}{19}{Trailing Edge Scoring Architectures}{subsubsection.3.1.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces \textbf  {Example Trailing Edge Score}. This trailing edge score was produced by the Residual architecture. A darker pixel means that it is more likely to be part of the trailing edge.\relax }}{20}{figure.caption.18}}
\newlabel{fig:example_te_score_annotres}{{3.5}{20}{\textbf {Example Trailing Edge Score}. This trailing edge score was produced by the Residual architecture. A darker pixel means that it is more likely to be part of the trailing edge.\relax }{figure.caption.18}{}}
\citation{long2015fully}
\citation{long2015fully}
\citation{he2015deep}
\@writefile{toc}{\contentsline {paragraph}{Simple}{21}{section*.19}}
\@writefile{toc}{\contentsline {paragraph}{Upsample}{21}{section*.20}}
\@writefile{toc}{\contentsline {paragraph}{Jet}{21}{section*.21}}
\@writefile{toc}{\contentsline {paragraph}{Residual}{21}{section*.22}}
\newlabel{fig:te_simple}{{3.6a}{22}{Subfigure 3 3.6a}{subfigure.3.6.1}{}}
\newlabel{sub@fig:te_simple}{{(a)}{a}{Subfigure 3 3.6a\relax }{subfigure.3.6.1}{}}
\newlabel{fig:te_residual}{{3.6b}{22}{Subfigure 3 3.6b}{subfigure.3.6.2}{}}
\newlabel{sub@fig:te_residual}{{(b)}{b}{Subfigure 3 3.6b\relax }{subfigure.3.6.2}{}}
\newlabel{fig:te_upsample}{{3.6c}{22}{Subfigure 3 3.6c}{subfigure.3.6.3}{}}
\newlabel{sub@fig:te_upsample}{{(c)}{c}{Subfigure 3 3.6c\relax }{subfigure.3.6.3}{}}
\newlabel{fig:te_jet}{{3.6d}{22}{Subfigure 3 3.6d}{subfigure.3.6.4}{}}
\newlabel{sub@fig:te_jet}{{(d)}{d}{Subfigure 3 3.6d\relax }{subfigure.3.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces \textbf  {Trailing Edge Scores}. These are the trailing edge scores given by each of the networks described in Section \ref  {sec:te_arch} on the image used in Figure \ref  {fig:example_te_score_annotres}. A darker pixel is predicted to be part of the trailing edge by the network.\relax }}{22}{figure.caption.23}}
\newlabel{fig:example_te_scores_all}{{3.6}{22}{\textbf {Trailing Edge Scores}. These are the trailing edge scores given by each of the networks described in Section \ref {sec:te_arch} on the image used in Figure \ref {fig:example_te_score_annotres}. A darker pixel is predicted to be part of the trailing edge by the network.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.2}Using the trailing edge scores}{22}{subsubsection.3.1.3.2}}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.3}Training Details}{23}{subsubsection.3.1.3.3}}
\citation{long2015fully}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf  {Trailing Edge Scoring Failure}. Unfortunately even the Residual architecture is still imperfect, and can lead to catastrophic trailing edge failures like this one. However this is a rare case.\relax }}{24}{figure.caption.24}}
\newlabel{fig:example_te_res_failure}{{3.7}{24}{\textbf {Trailing Edge Scoring Failure}. Unfortunately even the Residual architecture is still imperfect, and can lead to catastrophic trailing edge failures like this one. However this is a rare case.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.4}Evaluation}{24}{subsubsection.3.1.3.4}}
\citation{rakthanmanon2012searching,salvador2007fastdtw,lemire2009faster}
\citation{crow1984summed}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces \textbf  {Evaluating Trailing Edge Scoring Architectures}. Table showing the precision, recall, and IoU of each of the evaluated trailing edge scorers on each section of the trailing edge dataset. For the purposes of this analysis, we use the \texttt  {argmax} over the classes to determine a positive (i.e. trailing edge) or negative pixel.\relax }}{25}{table.caption.25}}
\newlabel{tab:te_score_full_analysis}{{3.1}{25}{\textbf {Evaluating Trailing Edge Scoring Architectures}. Table showing the precision, recall, and IoU of each of the evaluated trailing edge scorers on each section of the trailing edge dataset. For the purposes of this analysis, we use the \texttt {argmax} over the classes to determine a positive (i.e. trailing edge) or negative pixel.\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Trailing Edge Matching}{25}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Curvature Measurement}{26}{subsection.3.2.1}}
\newlabel{eqn:sat}{{3.9}{26}{Curvature Measurement}{equation.3.2.9}{}}
\newlabel{eqn:sat_area}{{3.10}{26}{Curvature Measurement}{equation.3.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces \textbf  {Trailing Edge Curvature}. The top images are of the same individual, and the bottom visualizations show the corresponding curvatures for their extracted trailing edges. Each row in the curvature visualization is a curvature scale, increasing from top to bottom. A darker blue implies a ``valley'' in the trailing edge (i.e.\ a higher curvature value), whereas lighter blue implies a ``peak'' (resp.\ a lower curvature value).\relax }}{27}{figure.caption.26}}
\newlabel{fig:example_curv}{{3.8}{27}{\textbf {Trailing Edge Curvature}. The top images are of the same individual, and the bottom visualizations show the corresponding curvatures for their extracted trailing edges. Each row in the curvature visualization is a curvature scale, increasing from top to bottom. A darker blue implies a ``valley'' in the trailing edge (i.e.\ a higher curvature value), whereas lighter blue implies a ``peak'' (resp.\ a lower curvature value).\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Sequence Matching}{27}{subsection.3.2.2}}
\newlabel{eqn:dtw_dist}{{3.11}{27}{Sequence Matching}{equation.3.2.11}{}}
\newlabel{eqn:dtw_update}{{3.12}{27}{Sequence Matching}{equation.3.2.12}{}}
\citation{sakoe1978dynamic}
\citation{muller2007information}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Alternative Approaches}{28}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Aligning Trailing Edges}{28}{subsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \textbf  {Example Matches}. The left side shows a success case, and the right side shows a failure case.\relax }}{29}{figure.caption.27}}
\newlabel{fig:example_match}{{3.9}{29}{\textbf {Example Matches}. The left side shows a success case, and the right side shows a failure case.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.1}Keypoint Alignment}{29}{subsubsection.3.3.1.1}}
\citation{qiao2006affine}
\citation{kumar2012leafsnap}
\citation{schroff2015facenet}
\citation{parkhi2015deep}
\citation{huang2007labeled}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1.2}Dynamic Time Warping Alignment}{30}{subsubsection.3.3.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Histogram Matching}{30}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Embedding via Convolutional Networks}{30}{subsection.3.3.3}}
\newlabel{sec:embedding}{{3.3.3}{30}{Embedding via Convolutional Networks}{subsection.3.3.3}{}}
\citation{schroff2015facenet}
\citation{hadsell2006dimensionality}
\citation{van2011numpy}
\citation{bergstra+al:2010-scipy,Bastien-Theano-2012}
\citation{sander_dieleman_2015_27878}
\citation{eigenweb}
\@writefile{toc}{\contentsline {chapter}{\numberline {4.}Results}{32}{chapter.4}}
\newlabel{sec:results}{{4}{32}{Results}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Main method}{32}{section.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces \textbf  {Itemized Running Time}. This table provides the average time taken for each operation that constitutes our algorithm on a single image. All computations were done on the subset of Flukebook that we used for evaluation (942 images).\relax }}{33}{table.caption.28}}
\newlabel{tab:extract_te_times}{{4.1}{33}{\textbf {Itemized Running Time}. This table provides the average time taken for each operation that constitutes our algorithm on a single image. All computations were done on the subset of Flukebook that we used for evaluation (942 images).\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Implementation}{33}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Running Time}{33}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Extracting Trailing Edges}{33}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Matching Trailing Edges}{34}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Configuration Options}{34}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Variability in Matching Score}{34}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf  {Score Separability Histogram}. The blue bars in this figure represent true matches, and the red bars represent false matches. The line at $\text  {score} = 0.88$ represents the optimal threshold at which to accept a match, although we can see it is not perfect.\relax }}{35}{figure.caption.29}}
\newlabel{fig:score_sep}{{4.1}{35}{\textbf {Score Separability Histogram}. The blue bars in this figure represent true matches, and the red bars represent false matches. The line at $\text {score} = 0.88$ represents the optimal threshold at which to accept a match, although we can see it is not perfect.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Effectiveness of Keypoint Extractor}{35}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf  {Varying Manual Extraction}. There is a small difference in matching accuracy between using the manually annotated points (red) provided for this dataset versus the keypoint extractor's predicted points (cyan). The bottom of the notch keypoint is not used in these evaluations.\relax }}{36}{figure.caption.30}}
\newlabel{fig:vary_manual_extract}{{4.2}{36}{\textbf {Varying Manual Extraction}. There is a small difference in matching accuracy between using the manually annotated points (red) provided for this dataset versus the keypoint extractor's predicted points (cyan). The bottom of the notch keypoint is not used in these evaluations.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Cropping Width}{36}{subsection.4.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \textbf  {Distribution of Unresized Trailing Edge Lengths}. This shows a significant distribution of trailing edges centered around a width of 800 pixels.\relax }}{37}{figure.caption.31}}
\newlabel{fig:width_te_dist}{{4.3}{37}{\textbf {Distribution of Unresized Trailing Edge Lengths}. This shows a significant distribution of trailing edges centered around a width of 800 pixels.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Trailing Edge Scorer Architecture}{37}{subsection.4.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces \textbf  {Varying $w$}. Note that we use the manually annotated points in this analysis to control for any issues with keypoint extraction.\relax }}{38}{figure.caption.32}}
\newlabel{fig:vary_crop_size}{{4.4}{38}{\textbf {Varying $w$}. Note that we use the manually annotated points in this analysis to control for any issues with keypoint extraction.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces \textbf  {Trailing Edge Scorer Architectures}. The highest performing trailing edge scorer (Residual) is shown in red, followed by Simple, Jet, and Upsample (in descending order of accuracy).\relax }}{39}{figure.caption.33}}
\newlabel{fig:vary_te_scorer}{{4.5}{39}{\textbf {Trailing Edge Scorer Architectures}. The highest performing trailing edge scorer (Residual) is shown in red, followed by Simple, Jet, and Upsample (in descending order of accuracy).\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces \textbf  {Trailing Edge Scorer Architectures at $\beta = 1$}. Upsample (cyan) performs significantly worse than the other networks, which all perform comparably.\relax }}{39}{figure.caption.34}}
\newlabel{fig:vary_te_scorer_maxweight}{{4.6}{39}{\textbf {Trailing Edge Scorer Architectures at $\beta = 1$}. Upsample (cyan) performs significantly worse than the other networks, which all perform comparably.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Using a Trailing Edge Scorer}{39}{subsection.4.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces \textbf  {Varying $\beta $}. Setting $\beta = 0.5$ (yellow) provides only marginally better results over any other non-zero value of $\beta $, but is significantly better than $\beta = 0$ (purple).\relax }}{40}{figure.caption.35}}
\newlabel{fig:vary_te_weight}{{4.7}{40}{\textbf {Varying $\beta $}. Setting $\beta = 0.5$ (yellow) provides only marginally better results over any other non-zero value of $\beta $, but is significantly better than $\beta = 0$ (purple).\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Number of neighbors in the extraction}{40}{subsection.4.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces \textbf  {Example Use of Trailing Edge Scorer}. In (a), we have the trailing edge extracted with the Residual scorer. Compare to (b), which did not use any scorer at all, resulting in a match failure.\relax }}{41}{figure.caption.36}}
\newlabel{fig:dis_te_use}{{4.8}{41}{\textbf {Example Use of Trailing Edge Scorer}. In (a), we have the trailing edge extracted with the Residual scorer. Compare to (b), which did not use any scorer at all, resulting in a match failure.\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}Using the notch}{41}{subsection.4.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces \textbf  {Varying $n$}. This shows that the optimal neighborhood constraint is $n = 3$ (purple), despite qualitatively producing worse-looking trailing edges. After $n = 5$ (blue), the trailing edges can become very noisy affecting match accuracy.\relax }}{42}{figure.caption.37}}
\newlabel{fig:vary_neighbors}{{4.9}{42}{\textbf {Varying $n$}. This shows that the optimal neighborhood constraint is $n = 3$ (purple), despite qualitatively producing worse-looking trailing edges. After $n = 5$ (blue), the trailing edges can become very noisy affecting match accuracy.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.8}Curvature Scales}{42}{subsection.4.4.8}}
\newlabel{fig:curvature_diversity:a}{{4.10a}{43}{Subfigure 4 4.10a}{subfigure.4.10.1}{}}
\newlabel{sub@fig:curvature_diversity:a}{{(a)}{a}{Subfigure 4 4.10a\relax }{subfigure.4.10.1}{}}
\newlabel{fig:curvature_diversity:b}{{4.10b}{43}{Subfigure 4 4.10b}{subfigure.4.10.2}{}}
\newlabel{sub@fig:curvature_diversity:b}{{(b)}{b}{Subfigure 4 4.10b\relax }{subfigure.4.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces \textbf  {Curvature Diversity}. Left panel (a) shows the average standard deviation of the (fixed length) curvature at different scales. Right panel (b) shows the average Euclidean distance between curvatures measured at successive scales.\relax }}{43}{figure.caption.38}}
\newlabel{fig:curvature_diversity}{{4.10}{43}{\textbf {Curvature Diversity}. Left panel (a) shows the average standard deviation of the (fixed length) curvature at different scales. Right panel (b) shows the average Euclidean distance between curvatures measured at successive scales.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.9}Sakoe-Chiba bound}{43}{subsection.4.4.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces \textbf  {Varying Sakoe-Chiba Bound}. We achieve good results with the Sakoe-Chiba bound set to $10\%$ (yellow), although we can get slightly better results with it set to $50\%$ (green) at the expense of computation time.\relax }}{44}{figure.caption.39}}
\newlabel{fig:vary_window}{{4.11}{44}{\textbf {Varying Sakoe-Chiba Bound}. We achieve good results with the Sakoe-Chiba bound set to $10\%$ (yellow), although we can get slightly better results with it set to $50\%$ (green) at the expense of computation time.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces \textbf  {Example Disagreements Between Hotspotter and our method}. On the left side, (a) was matched correctly to (c) by our method, whereas Hotspotter could not find any matches for (a). On the right hand side however, Hotspotter gave (d) as the top match for (b) despite a large variance in pose and lighting, while our method failed to rank (d) in the top 5 matches for (b).\relax }}{44}{figure.caption.40}}
\newlabel{fig:dis_proot}{{4.12}{44}{\textbf {Example Disagreements Between Hotspotter and our method}. On the left side, (a) was matched correctly to (c) by our method, whereas Hotspotter could not find any matches for (a). On the right hand side however, Hotspotter gave (d) as the top match for (b) despite a large variance in pose and lighting, while our method failed to rank (d) in the top 5 matches for (b).\relax }{figure.caption.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces \textbf  {Comparison with Hotspotter}. This table provides a comparison between our method and Hotspotter in terms of top-1 ranking accuracy on the Flukebook dataset.\relax }}{45}{table.caption.41}}
\newlabel{tab:vary_proot}{{4.2}{45}{\textbf {Comparison with Hotspotter}. This table provides a comparison between our method and Hotspotter in terms of top-1 ranking accuracy on the Flukebook dataset.\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}In Combination with Hotspotter}{45}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Characterization of when to use which method}{45}{subsection.4.5.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5.}Discussion}{47}{chapter.5}}
\newlabel{sec:discussion}{{5}{47}{Discussion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Issues with the Proposed Method}{47}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces \textbf  {Histogram of Ground-Truth Ranks}. Note that the histogram ranges are uneven to better show the lower end of the range. In order to have all matches found within the top-$k$ matches we would have to set $k = 414$.\relax }}{48}{figure.caption.42}}
\newlabel{fig:gtrank_hist}{{5.1}{48}{\textbf {Histogram of Ground-Truth Ranks}. Note that the histogram ranges are uneven to better show the lower end of the range. In order to have all matches found within the top-$k$ matches we would have to set $k = 414$.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces \textbf  {Histogram of Score Differences between 1st and 2nd Rank}. Note that the histogram ranges are uneven to better show the higher end of the range.\relax }}{49}{figure.caption.43}}
\newlabel{fig:score_diff1st2nd}{{5.2}{49}{\textbf {Histogram of Score Differences between 1st and 2nd Rank}. Note that the histogram ranges are uneven to better show the higher end of the range.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Future work}{49}{section.5.2}}
\citation{hughes2015automated}
\bibstyle{abbrv}
\bibdata{references}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Conclusion}{50}{section.5.3}}
\bibcite{akagi2013facial}{{1}{}{{}}{{}}}
\bibcite{amini1988using}{{2}{}{{}}{{}}}
\bibcite{Avidan:2007:SCC:1276377.1276390}{{3}{}{{}}{{}}}
\bibcite{baker1993abundant}{{4}{}{{}}{{}}}
\bibcite{Bastien-Theano-2012}{{5}{}{{}}{{}}}
\bibcite{beekmans2005comparison}{{6}{}{{}}{{}}}
\bibcite{bergstra+al:2010-scipy}{{7}{}{{}}{{}}}
\bibcite{berretti20113d}{{8}{}{{}}{{}}}
\bibcite{blackmer2000temporal}{{9}{}{{}}{{}}}
\bibcite{branch2011humpback}{{10}{}{{}}{{}}}
\bibcite{calambokidis2008splash}{{11}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{REFERENCES}{52}{section*.45}}
\bibcite{chen2014semantic}{{12}{}{{}}{{}}}
\bibcite{ciresan2012deep}{{13}{}{{}}{{}}}
\bibcite{crall_hotspotter_2013}{{14}{}{{}}{{}}}
\bibcite{crow1984summed}{{15}{}{{}}{{}}}
\bibcite{sander_dieleman_2015_27878}{{16}{}{{}}{{}}}
\bibcite{dumoulin2016guide}{{17}{}{{}}{{}}}
\bibcite{fan2014learning}{{18}{}{{}}{{}}}
\bibcite{fischer2014image}{{19}{}{{}}{{}}}
\bibcite{fukushima1979neural}{{20}{}{{}}{{}}}
\bibcite{eigenweb}{{21}{}{{}}{{}}}
\bibcite{hadsell2006dimensionality}{{22}{}{{}}{{}}}
\bibcite{hariharan2014simultaneous}{{23}{}{{}}{{}}}
\bibcite{i3scontour}{{24}{}{{}}{{}}}
\bibcite{he2015deep}{{25}{}{{}}{{}}}
\bibcite{hinton2012improving}{{26}{}{{}}{{}}}
\bibcite{huang2007labeled}{{27}{}{{}}{{}}}
\bibcite{huele2000finding}{{28}{}{{}}{{}}}
\bibcite{hughes2015automated}{{29}{}{{}}{{}}}
\bibcite{ioffe2015batch}{{30}{}{{}}{{}}}
\bibcite{jaderberg2015spatial}{{31}{}{{}}{{}}}
\bibcite{kass1988snakes}{{32}{}{{}}{{}}}
\bibcite{kingma2014adam}{{33}{}{{}}{{}}}
\bibcite{kniest2010fluke}{{34}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{35}{}{{}}{{}}}
\bibcite{kumar2012leafsnap}{{36}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{37}{}{{}}{{}}}
\bibcite{lemire2009faster}{{38}{}{{}}{{}}}
\bibcite{long2015fully}{{39}{}{{}}{{}}}
\bibcite{lowe2004distinctive}{{40}{}{{}}{{}}}
\bibcite{mizroch1990computer}{{41}{}{{}}{{}}}
\bibcite{monroy2011beyond}{{42}{}{{}}{{}}}
\bibcite{muller2007information}{{43}{}{{}}{{}}}
\bibcite{munich1999continuous}{{44}{}{{}}{{}}}
\bibcite{ning2005toward}{{45}{}{{}}{{}}}
\bibcite{nouri2014using}{{46}{}{{}}{{}}}
\bibcite{parkhi2015deep}{{47}{}{{}}{{}}}
\bibcite{pottmann2007integral}{{48}{}{{}}{{}}}
\bibcite{qiao2006affine}{{49}{}{{}}{{}}}
\bibcite{rakthanmanon2012searching}{{50}{}{{}}{{}}}
\bibcite{sakoe1978dynamic}{{51}{}{{}}{{}}}
\bibcite{salvador2007fastdtw}{{52}{}{{}}{{}}}
\bibcite{saxe2013exact}{{53}{}{{}}{{}}}
\bibcite{schroff2015facenet}{{54}{}{{}}{{}}}
\bibcite{sermanet2013overfeat}{{55}{}{{}}{{}}}
\bibcite{simonyan2014very}{{56}{}{{}}{{}}}
\bibcite{Sobel1968}{{57}{}{{}}{{}}}
\bibcite{sun2013deep}{{58}{}{{}}{{}}}
\bibcite{szegedy2015going}{{59}{}{{}}{{}}}
\bibcite{taigman2014deepface}{{60}{}{{}}{{}}}
\bibcite{van2011numpy}{{61}{}{{}}{{}}}
\bibcite{whitehead1990computer}{{62}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
